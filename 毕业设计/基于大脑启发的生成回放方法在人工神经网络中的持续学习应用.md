# Articles

人工神经网络面临灾难性遗忘问题。与人类不同，当这些网络在新任务上进行训练时，它们会迅速忘记之前学到的内容。在大脑中，一种被认为对保护记忆至关重要的机制是重新激活代表这些记忆的神经活动模式。在人工神经网络中，这种记忆回放可以通过“生成回放”来实现，这种方法可以成功且令人惊讶地高效地防止灾难性遗忘，即使在类增量学习的场景中也能取得良好效果。然而，将生成回放扩展到复杂的任务或复杂输入的问题仍然充满挑战。我们提出了一种新的、大脑启发的回放变体，其中通过网络自身的、受上下文调节的反馈连接生成并重现内部或隐藏表示。我们的方法在具有挑战性的持续学习基准测试（例如，在CIFAR-100上的类增量学习）中取得了最先进的表现，且无需存储数据，并为大脑中的回放机制提供了一个新颖的模型。


当前最先进的深度神经网络能够在各种任务上训练出令人印象深刻的表现。但是，当这些网络在新任务上进行训练时，之前学到的任务通常会被迅速遗忘。重要的是，这种“灾难性遗忘”并不是由于网络容量有限，因为同样的网络在交替训练的情况下可以学习许多任务。然而，在现实世界中，训练示例并不是交替呈现的，而是以有时间相关性的顺序出现。一种解决方案是存储以前遇到的示例，并在学习新内容时重新访问它们。尽管这种“回放”或“复述”可以解决灾难性遗忘问题，但这种解决方案的可扩展性一直受到质疑，因为不断对所有已学任务进行再训练非常低效，而且必须存储的数据量很快会变得无法管理。然而，在大脑中——大脑显然实现了一种高效且可扩展的持续学习算法——重新激活代表过去经验的神经活动模式被认为对稳定新记忆至关重要。这样的记忆回放由海马体协调，但也在大脑皮层中被观察到，主要发生在睡眠和清醒状态下的尖波/波动过程中。受到这一启发，本文重新审视了将回放作为人工神经网络（ANNs）持续学习工具的使用。

如上所述，向ANN中添加回放的直接方法是使用从以前学习任务中存储的数据，并将其与当前任务的训练数据交替使用。然而，依赖存储数据存在许多不希望遇到的情况。首先，从机器学习的角度来看，存储数据并不总是可行的（例如，由于安全性或隐私问题），而且在面对大量任务的问题时，这也是一个问题。其次，从神经科学的角度来看，如果我们希望将ANN中的回放作为大脑中再激活的模型，使用存储数据是不合适的，因为存储数据（例如，图像的所有像素）在大脑中直接存储的方式是值得怀疑的，而根据经验，显然人类记忆并不完美。作为存储数据的替代方案，本文着重于通过学习的生成神经网络模型来生成待回放的数据，这些数据来源于过去的观察。

近期的证据表明，根据持续学习问题的设置，回放甚至可能是不可避免的。通常，持续学习是在任务增量学习（Task-IL）场景中进行研究的，在这种场景中，代理必须逐步学习执行多个不同的任务。尽管这对于许多强化学习问题来说是一个自然的场景（例如，逐步学习玩Atari游戏），但对于分类问题，这种场景通常是人为的。假设一个代理首先学习分类猫和狗，然后学习分类牛和马。似乎可以合理地预期，代理现在也应该能够区分猫和牛。然而，在Task-IL场景中，代理仅需能够解决其训练过的精确分类任务。在类增量学习（Class-IL）场景中，才要求区分来自不同学习任务的类。尽管这个区别看起来微妙，但实际上它显著影响了持续学习问题的难度：现有的持续学习算法在Class-IL场景中，即使在看似简单的玩具示例上也会失败。生成回放（GR）目前是唯一能够在不存储数据的情况下在这个场景中表现良好的方法。

然而，GR的一个重要潜在缺点是，将其扩展到更具挑战性的问题已被报告为具有挑战性。因此，Class-IL问题在更复杂的输入（例如自然图像）上仍是深度学习中的一个开放问题，因为在这些问题上，只有显式存储数据的方法才能达到可接受的表现。此外，从神经科学的角度来看，回放在生物学上不可扩展的问题（即在不存储数据的情况下）令人困惑，因为它提出了一个问题：回放如何在大脑中支持记忆巩固。

在这里，我们挑战了GR的不可扩展性。在首先确认回放对于Class-IL的重要性后，我们报告了在MNIST数据集上的实验，突显了回放的惊人效率和稳健性：仅回放少量或低质量的样本就足够了。然而，尽管在手写数字的实验中取得了有希望的结果，我们还发现将GR扩展到更复杂的问题并不简单。为了解决这一问题，我们提出了一种新的GR变体，其中通过网络自身的、受上下文调节的反馈连接生成并回放内部或隐藏表示。我们证明，这种受大脑启发的回放方法在具有许多任务（≥100个）或复杂输入（自然图像）的具有挑战性的持续学习基准上，取得了最先进的表现，并且无需存储数据。

>[!figure]
![[files/Pasted image 20241230223849.png]]
**当前将回放添加到人工神经网络的方法如何映射到大脑的示意图**  
**精确回放或经验回放**，将海马体视为一个记忆缓冲区，其中经验可以简单地存储，这类似于传统的情节记忆的观点。  
**生成回放与独立的生成模型**，将海马体视为一个生成神经网络，而回放则视为一种生成过程。


# 结果
### 比较持续学习方法
我们的第一个目标是将生成回放（GR）与已有的持续学习方法进行比较。为此，本文以及后续研究均聚焦于基于图像分类的持续学习问题。为了量化性能，我们使用了迄今为止所有任务或类的平均测试准确率。关于这一衡量标准的理由及本研究范围的更详细讨论，请参见讨论部分。

对于我们实现的生成回放（GR）方法，我们遵循了Shin等人提出的通用框架：除了用于解决任务的主模型（即分类器）外，还训练了一个单独的生成模型来生成待回放的数据（见图2）。我们使用了标准的变分自编码器（VAE）作为生成器（详见“方法”部分）。  缓解人工神经网络（ANNs）灾难性遗忘的另一种策略是保护对于先前学习任务重要的网络参数。两种广泛使用的基于正则化的方法是弹性权重巩固（EWC）和突触智能（SI）。这两种方法都为所有参数维护估计值，表示它们对先前任务表现的影响程度，然后在学习新任务时，利用这些估计值来惩罚对更有影响力的参数的改变。从神经科学的角度来看，这些方法可以被解释为受元可塑性启发的。  另一种近期受到神经科学启发的持续学习方法是基于上下文的门控（XdG）。为了减少任务之间的干扰，这种方法为每个任务选择一个不同的、随机选定的网络节点子集进行门控。XdG的一个重要限制是，它假设要执行的特定任务总是已知的，这意味着这种方法不能用于类增量学习（Class-IL）。我们考虑的最后一种持续学习方法是**“无遗忘学习”（LwF）**。这种方法与基于回放的方法有一个有趣的联系：它并不存储或生成待回放的数据，而是在标记当前任务的输入之后，使用先前任务训练的模型进行回放。

>[!figure] 
>![[files/Pasted image 20241230225126.png]]\
>图 2 生成重放训练人工神经网络的协议。  
a. 在第一个任务上，主模型 [M] 和一个独立的生成器 [G] 被正常训练。当进入新的任务时，这两个训练好的模型首先生成要重放的样本（见 (b)）。这些生成的样本随后与当前任务的训练数据一起进行重放，两个模型都会在这个扩展数据集上继续训练。  
b. 为了生成要重放的样本，首先从训练好的生成器中采样代表前一个任务的输入，然后根据训练好的主模型对这些输入的预测进行标注。

### 类增量学习可能需要重放。
为了比较这些持续学习方法，我们首先使用了一个流行的深度学习示例——分类MNIST数字（参见文献33）。当在所有数字上同时训练时，这是一个非常简单的问题，现代深度神经网络几乎不会犯错。但当数据集被拆分成多个任务或必须按顺序学习的多个阶段时，这个问题变得相当困难。这种任务协议被称为**split MNIST**（图 3a）。尽管近年来它已经成为一个流行的持续学习基准，但并不是所有人都意识到，这种协议可以以多种方式设置[或根据不同的‘场景’24]。一种选择是网络只需要学习解决每个单独的任务，这意味着在测试时总是能明确知道待分类的数字来自哪个任务（即，选择总是仅限于两个可能的数字之间）。这就是**Task-IL场景**（文献24）或‘多头’设置（文献22）。另一种，可能更现实的选择是，网络最终必须学会区分所有十个数字。以这种方式设置，**split MNIST** 变成了**Class-IL问题**。网络必须学习一个10类分类器，但每次只观察到两个类别。这个更具挑战性的场景也被称为‘单头’设置（文献22）。

>[!info]
>### 1. **Task-IL（任务增量学习，Multi-headed setup）**
在 **Task-IL** 设置中，模型在每次训练时只需要学会识别当前任务中的两个数字，且在测试时总是能够知道待分类的数字属于哪个任务。这意味着每次训练时，任务是**独立的**，模型只需要处理当前任务的两个数字。换句话说，模型不会在一个任务中混淆不同任务的类别。
**例子：** 假设我们将 MNIST 数据集分成 5 个任务，每个任务包含 2 个数字：
>- 任务 1：数字 0 和数字 1
>- 任务 2：数字 2 和数字 3
>- 任务 3：数字 4 和数字 5
>- 任务 4：数字 6 和数字 7
>- 任务 5：数字 8 和数字 9
>
>在 **Task-IL** 设置中，网络每次学习一个任务，只会接触到该任务中的两个数字。例如，在任务 1 的训练阶段，网络只会见到数字 0 和数字 1。当它学习任务 2 时，只会接触到数字 2 和数字 3。测试时，模型会明确知道当前测试的数字属于哪个任务（例如，任务 1 只包含 0 和 1，任务 2 只包含 2 和 3），因此它只需从当前任务的两个数字中做出选择。
这种设置的关键特点是 **每个任务只包含两个类别**，任务之间是隔离的，模型在训练时不会混淆任务。
>### 2. **Class-IL（类增量学习，Single-headed setup）**
在 **Class-IL** 设置中，模型的目标是逐渐学会区分所有类别，但每次训练时只接触到两个类别。换句话说，虽然网络最终需要学习区分 10 个数字，但每次只会看到其中的两个数字进行训练。随着任务的增加，网络会逐渐扩展其分类能力，但它始终只能处理有限的类别。
**例子：** 假设我们将 MNIST 数据集分成 5 个任务，每个任务包含 2 个数字，网络需要学会识别所有 10 个数字，但每次只能看到其中的两个：
>- 任务 1：数字 0 和数字 1
>- 任务 2：数字 2 和数字 3
>- 任务 3：数字 4 和数字 5
>- 任务 4：数字 6 和数字 7
>- 任务 5：数字 8 和数字 9

在这两种 **split MNIST** 场景中，我们将 **GR（生成重放）** 的实现与 **EWC**、**SI** 和 **LwF** 进行了比较，并且在 **Task-IL** 场景下还与 **XdG** 进行了比较。作为基准方法，我们还包括了以下两种：一种是简单地对每个新任务进行标准方式的微调（**None**），另一种是始终使用迄今为止所有任务的数据来训练网络（**Joint**，可以视为上限）。为了公平比较，所有方法都使用了类似大小的网络，并且采用相同的训练方法。

>[!notice]
>- **GR**：生成重放（Generative Replay），是一种通过生成器生成过去任务数据并与当前任务数据一起训练的方法，用来防止灾难性遗忘。
>- **EWC**：弹性权重固定（Elastic Weight Consolidation），通过对网络的权重加上惩罚项，来防止在训练新任务时过度改变已学习的旧任务知识。
>- **SI**：稳定性塑性（Synaptic Intelligence），类似于 EWC，通过对网络的权重进行调整，保持旧任务的稳定性。
>- **LwF**：学习通过反馈（Learning without Forgetting），通过在训练新任务时保持旧任务的输出一致性来避免遗忘。
>- **XdG**：通过为每个任务选择一个不同的、随机选取的子集的网络节点来“门控”任务之间的干扰，从而避免任务间的干扰。
>
**None** 和 **Joint** 分别代表了两种极端情况：
>- **None**：表示没有使用任何增量学习方法，每个任务都会重新开始训练，之前学过的知识不被保留。
>- **Joint**：表示网络在训练每个新任务时都会使用所有任务的训练数据，这种方法通常被视为增量学习中的**上限**，因为它不会丢失任何旧任务的信息。

与近期的研究报告一致（文献21-24），我们发现，对于大多数比较的方法，两个场景之间的性能差异非常显著。在 **Task-IL** 场景中，当任务必须按增量方式学习时，所有比较的方法都成功地防止了灾难性遗忘（图 3b）。然而，令人吃惊的是，在 **Class-IL** 场景中，当类别必须按增量方式学习时，受元可塑性启发的方法（**EWC** 和 **SI**）显著失败，只有 **GR**（生成重放）能够成功学习所有数字（图 3c）。这表明，在 **Class-IL** 场景中，当网络必须学习区分那些不一起出现的类别时，可能需要某种形式的重放技术。

### 生成重放（GR）的效率与鲁棒性

这些结果突出了 **生成重放（GR）** 作为一种有前景的方法，甚至可能是人工神经网络（ANNs）持续学习中不可避免的工具。然而，尽管重放生成的数据避免了必须存储大量数据的问题，但一个未解决的担忧是，不断对所有先前任务进行重新训练是非常低效的。确实，对于 **GR** 的一个简单实现，在这种实现中，会为所有先前任务生成完整的伪数据集并将其与当前任务的训练集拼接，这种低效问题是显而易见的。然而，重要的是，使用重放并不一定意味着要对所有先前任务进行完全重新训练。例如，在本文中使用的 **GR** 实现中，每次迭代只重放固定数量的样本。因此，重放样本的总数并不依赖于先前任务的数量。在图 3 中的实验中，每次迭代基于一个包含 128 个当前任务样本和 128 个重放样本（这些样本在先前任务中进行划分）的 **mini-batch**。为了测试是否可以进一步减少重放样本的数量，我们进行了额外的实验，系统地改变了每个 **mini-batch** 中重放的样本数。结果表明，**GR** 的性能相对稳健（见图 4a 中的红线）：即使每个 **mini-batch** 只重放一个样本（即，每 128 个当前任务样本中只重放一个样本），**GR** 在 **Task-IL** 场景中依然表现出竞争力，并且在 **Class-IL** 场景中超越了所有非重放方法。

**生成重放（GR）的另一个常见批评**是它只是将**灾难性遗忘**问题转移到了**生成模型的训练**上（参考文献 7，第3页）。这里的担忧在于，训练生成模型本身也是一个困难的问题。换句话说，虽然可能可以训练一个能够生成逼真 MNIST 图像的模型，但对于具有更复杂输入的实际问题，训练高质量的生成模型可能既困难又计算开销巨大。确实，需要训练一个额外的生成模型是 **GR** 的一个劣势。但是，这个生成模型的质量到底有多重要呢？有一个初步的迹象表明，重放不必完美就能有用。这个迹象来自于 **LwF（Learning without Forgetting）** 在 **split MNIST** 协议中的合理表现：重放当前任务的输入——例如，重放 '2' 和 '3'，以避免忘记 '0' 和 '1'——比 **EWC** 和 **SI** 方法表现得更好（图 3b, c）。然后，为了更进一步、系统地测试重放的质量到底需要多高，我们改变了用于生成重放的 VAE 模型中隐藏单元的数量。令人惊讶的是，将 VAE 的隐藏层减少到仅有 10 个单元时，生成的样本质量较低（图 4c 左侧面板），但这只对 **GR** 的表现产生了适度的影响（图 4b）。

>[!figure]
>![[files/Pasted image 20250104171613.png]]
>**图 3** 生成重放可能是人工神经网络增量学习新类别所需的。  
>- a. **split MNIST** 任务协议在两种不同场景下的形式。  
>- b. 在 **任务增量学习场景**（**Task-IL**）中，所有比较的持续学习方法表现都非常好。  
>- c. 在 **类增量学习场景**（**Class-IL**）中，只有 **生成重放（GR）** 能有效防止灾难性遗忘。报告的是基于迄今为止所有任务/数字的平均测试准确率。显示的是 20 次重复实验的均值，阴影区域表示 ±1 标准误差（SEM）。



**为什么能够重放如此少量或低质量的示例？** 一个可能的原因是，学习新任务比保持已有知识更困难。这一直觉在一个对照实验中得到了验证。在这个实验中，我们**在每次训练新任务之前重新初始化了网络的参数**（但在重放样本生成后进行），这样网络每次都必须从头开始重新学习所有的旧任务（在图 4a 和 4b 中的棕色线条表示）。在这种情况下，仅重放少量或低质量的示例确实不足以实现与不重新初始化时相同的强大性能。

> [!figure]
> ![[files/Pasted image 20250104172609.png]]
> **图 4** 生成重放（GR）表现出显著的高效性和鲁棒性。通过显著减少重放样本的数量或质量，仍然能够保持较好的性能。
a、b 图展示了在 **split MNIST** 协议下，**生成重放** 在两种不同增量学习场景中的表现：任务增量学习场景（**Task-IL**，左）和类增量学习场景（**Class-IL**，右）。
> - **a 图** 展示了生成重放的平均测试准确率（基于所有任务/数字）作为每个 **mini-batch** 重放样本总数的函数。
> - **b 图** 展示了生成重放的平均测试准确率作为用于生成重放的变分自编码器（**VAE**）隐藏层单元数的函数。
> 
> 作为对照，还展示了一种生成重放的变体，其中网络在每次新任务/回合前都会重新初始化。  为便于比较，在每个图的左侧，显示了其他方法的平均测试准确率（参见图 3）。  数据显示的是 20 次重复实验的均值，阴影区域表示 ±1 标准误差（SEM）。
>**c 图** 展示了在完成第四个任务的训练后（即，展示在最后一个任务的训练中重放的示例）从生成模型中随机生成的样本，分别使用了 10、100 和 1000 个隐藏层单元的 VAE，展示了重放样本的低质量。




### 扩展到更具挑战性的问题
总结来说，**人工神经网络（ANNs）**中的灾难性遗忘问题可以通过相对少量的“足够好的”重放来避免。这表明，**生成重放（GR）** 有潜力在更具挑战性的实际持续学习问题中也能发挥作用。接下来，我们将进行测试，验证这一点。

**我们首先问了生成重放（GR）如何扩展到多任务问题中。** 为此，我们选择了 **Permuted MNIST** 协议（图 5a）作为测试用例，这也是一个常用的持续学习基准任务。该协议同样使用 MNIST 数据集，但每个任务都包含所有 10 个数字，并且每个任务对所有图像的像素应用了不同的排列。目标始终是识别原始数字（即进行 10 类分类）。通常，在测试时网络并不知道图像应用了哪种排列，这意味着任务是在 **Domain-IL** 场景下进行的。尽管通常 **Permuted MNIST** 只考虑有限数量的排列（≤10），但 Masse 等人最近的一项研究使用这个协议来评估当任务数量显著增加时，不同方法的表现。他们发现，在 100 个任务后，**突触智能（SI）** 和 **在线弹性权重固定（online EWC）**（EWC 的一种更高效版本）分别获得了约 82% 和 70% 的平均准确率。尽管他们提出的方法 **XdG** 本身表现比这两种方法差（约 61%），但他们发现通过将 **XdG** 与 **SI** 结合使用，**SI** 的性能可以显著提高（约 95%）。然而，值得注意的一点是，**XdG** 假设在测试时网络始终知道图像应用了哪种排列。也就是说，虽然 **SI** 和 **在线 EWC** 本身是在 **Domain-IL** 场景下进行的，但与 **XdG** 结合使用时，网络会在 **Task-IL** 场景下进行任务，即测试时可以获得额外的任务信息。换句话说，**XdG** 的性能提升依赖于测试时可获得的额外信息。

> [!figure]
>![[files/Pasted image 20250104191228.png]]
> **图 5** 大脑启发的修改使生成重放（GR）能够扩展到有多个任务的问题。
> - a. **Permuted MNIST 协议**，包含 100 个排列。  
> - b. 在 **Domain-IL 场景**（即测试时没有任务标签可用）下，当前表现最佳的方法是 **突触智能（SI）**。尽管标准的 **生成重放（GR）** 在前 10 个任务中超越了 **SI**，但其性能在大约 15 个任务后迅速下降。通过我们的大脑启发的修改（**BI-R**，见下文），生成重放在经过 100 个任务后仍然超越了 **SI**。将 **BI-R** 与 **SI** 结合使用可以进一步提升性能。由于任务之间的输入完全不相关，**不遗忘学习（LwF）** 在此任务协议中的表现很差。报告的是基于至今所有排列的平均测试准确率。显示的是 5 次重复实验的均值，阴影区域表示 ±1 标准误差（SEM）。


**第二个问题是，生成重放（GR）是否能够扩展到更复杂的输入问题。**为此，我们使用了 **CIFAR-100 数据集**，将其分为 10 个任务，每个任务包含 10 个自然图像类别（图 6a）。与 **split MNIST** 类似，这个任务协议的难度在不同场景下差异很大。
- **Task-IL 场景**（每次任务中只有 10 个类别）：我们发现，方法如 **EWC**、**SI** 和 **LwF** 在该场景下几乎完全避免了灾难性遗忘（图 6b）。然而，标准的 **GR** 在这个自然图像任务中表现较差，即使是在 **Task-IL** 场景下也未能有效防止灾难性遗忘。
- **Class-IL 场景**（任务的类别逐渐增加，最终是 100 类分类问题）：在 **Class-IL** 场景下，**split CIFAR-100 协议** 变得更加具有挑战性，所有比较的现有方法（包括 **GR**、**EWC**、**SI** 和 **LwF**）都表现不佳，遭遇了严重的灾难性遗忘（图 6c）。目前，唯一能够在这个基准测试中取得可接受性能的方法是 **显式存储数据** 的方法，如 **iCaRL** 或 **经验重放**。

> [!figure]
> ![[files/Pasted image 20250104191247.png]]
> **图 6** 大脑启发的修改使生成重放能够扩展到具有复杂输入的问题。
> **a**. **split CIFAR-100 协议** 在两种不同场景下的表现。  
> **b**. 在 **任务增量学习场景**（**Task-IL**）下，大多数持续学习方法表现良好，尽管标准的 **生成重放（GR）** 的表现甚至比简单基线差。但是，通过我们的大脑启发的修改（见下文），**GR** 超越了其他方法。  
> **c**. 在 **类增量学习场景**（**Class-IL**）下，任何不存储数据的现有持续学习方法都无法防止灾难性遗忘。我们的 **大脑启发的重放（BI-R）**，特别是与 **突触智能（SI）** 结合时，在这个具有挑战性的、尚未解决的基准任务上取得了合理的表现。  
> 报告的是基于所有任务/类别的平均测试准确率。显示的是 10 次重复实验的均值，阴影区域表示 ±1 标准误差（SEM）。  
> **d**. 在最终任务训练过程中，使用标准的生成重放进行重放的图像示例。  
> - **Joint**：使用迄今为止的所有数据进行训练（“上限”）。  
> - **LwF**（Learning without Forgetting）：不遗忘学习。  
> - **EWC**（Elastic Weight Consolidation）：弹性权重固定。  
> - **None**：标准方式进行顺序训练。

### 大脑启发的生成重放（GR）改进
这些结果与其他最近的研究报告一起表明，直接实现的生成重放（GR）在面对更具挑战性的问题时会出现失败。虽然我们之前发现重放生成的样本不需要完美，但似乎在这些问题中，生成的输入质量太低（图 6d）。一种可能的解决方法是，尝试利用深度神经网络在生成模型方面的最新进展来提高生成器的质量。尽管这种方法在某种程度上可能有效，但有一个问题是，增量训练高质量的生成模型本身就是一个非常具有挑战性的问题。更重要的是，这样的解决方案可能效率较低，因为当前最先进的生成模型通常需要非常高的计算成本来进行训练或从中采样。因此，考虑到大脑已经实现了一种高效的持续学习算法，据信该算法依赖于重放机制，我们转向了大脑作为灵感来源。

**我们对标准生成重放（GR）方法的第一次修改是基于大脑解剖学的启发。** 在大脑中，重放的过程始于**海马体**，然后传播到**大脑皮层**。对于当前版本的生成重放（GR），有研究提出，生成器作为重放的来源，类似于海马体，而主模型则对应于大脑皮层（图 1b）。虽然这种类比有一定道理，但一个问题是，它忽略了海马体实际上位于皮层之上，是大脑处理层级结构中的一部分。因此，我们提出将生成器**融合到主模型中**，并为其添加**生成的反向连接**或**反馈连接**。这样，模型的前几层可以被解释为对应于**视觉皮层的早期层**，而顶层则对应于**海马体**（图 7a）。我们将这种“通过反馈进行重放”的模型实现为一个带有**softmax 分类层**的**变分自编码器（VAE）**，并将该层添加到编码器的顶层（见“方法”部分）。

> [!figure]
> ![[files/Pasted image 20250104195608.png]]
> ![[files/Pasted image 20250104195618.png]]
> - **a. 通过反馈进行重放（Replay-through-feedback）**  
> 生成器通过添加**生成反馈或反向连接**与主模型融合。在这种修改中，生成器不再单独存在，而是与主模型紧密结合，形成一个端到端的模型，使得生成过程能够通过反馈来增强。
> 
> - **b. 条件重放（Conditional replay）**  
> 为了使模型能够生成特定类别的样本，标准的正态先验被替换为一个**高斯混合模型**，其中每个类别都有一个独立的模式。这使得生成器可以针对每个类别生成更具针对性的样本。
> 
> - **c. 基于内部上下文的门控（Gating based on internal context）**  
> 在每个任务或类别的学习过程中，**在生成的反向传递过程中，网络的每一层都会抑制一部分神经元**。这种门控机制基于任务或类别的内部上下文，有助于将任务隔离开来，减少任务间的干扰。
> 
> - **d. 内部重放（Internal replay）**  
> 与在输入层（如像素级别）重放表示不同，**在内部表示层进行重放**。这些表示通常是在网络的中间层或隐藏层生成的，能够帮助模型捕捉更抽象的特征，而不是仅仅依赖于原始输入的像素数据。

**标准VAE的一个问题**：  标准的**变分自编码器（VAE）** 无法**有意生成特定类别**的样本。然而，**人类**可以控制回忆起哪些记忆。为了让我们的模型能控制生成哪些类别，我们将 VAE 的**标准正态先验**改为一个**高斯混合模型**，每个类别有一个独立的分布（图 7b；见“方法”部分；也可参考文献 42）。这样，通过限制隐变量的采样范围在每个类别对应的分布上，我们可以生成特定的类别。此外，对于我们的 **通过反馈重放（RtF）** 模型，这种多模态先验可以帮助**更好地区分不同类别的内部表示**，因为它们不再都映射到一个单一的连续分布中。


**大脑根据上下文或任务的不同处理刺激**。研究表明，**上下文线索**（例如气味、声音）可以影响哪些记忆被重放。对于人工神经网络（ANN），实现上下文依赖处理的一种简单有效方法是**完全控制（或“抑制”）每个隐藏层中的一部分神经元**，这个神经元子集是根据当前任务随机选择的。这就是 **XdG**（上下文依赖性门控）方法。然而，正如上文所讨论的，这种技术只能在**任务标识信息始终可用**的情况下使用，这对于 **domain-IL** 或 **class-IL** 场景来说并不适用。我们意识到，在这些场景下，仍然可以使用上下文门控——尽管它仅限于**网络的解码器部分**，并且是基于**内部上下文**进行条件控制的。我们所依赖的**内部上下文**是要生成或重建的**特定任务或类别**（图 7c；见“方法”部分）。值得注意的是，这种方法是可行的，因为在推理过程中（即对新输入进行分类），只需要**前向传播层**，而这些层并没有进行门控。

我们的第四个也是最后一个大脑启发的修改是：不再将之前学习的类别表示重放到输入级别（例如像素级别），而是在网络的隐藏层进行重放（图7d；参见“方法”部分）。其动机是，大脑在回忆记忆时也不会将记忆完全传播回输入感官，例如，心理图像不会传递到视网膜。从机器学习的角度来看，这样的内部表示重放更容易实现，因为神经网络的早期层本来就是为了分解复杂的输入级别表示。实现这种内部重放策略的一个可能要求是，网络中不重放的前几层的变化非常小或几乎没有变化。从神经科学的角度来看，这种假设是合理的，因为大脑早期视觉区域提取的表示在成年后确实被认为不会发生显著变化。为了模拟这种发展过程，我们在 CIFAR-10 数据集上预训练了模型的卷积层，该数据集包含与 CIFAR-100 相似但不重叠的图像。在 CIFAR-100 的增量训练中，这些卷积层被冻结，我们仅通过全连接层进行重放。为了公平比较，在 CIFAR-100 的实验中，所有其他方法也使用了预训练的卷积层。由于在 split 和 permuted MNIST 中未使用卷积层，因此这些实验中未使用预训练和内部重放。

最后，我们还进行了一项受机器学习文献启发的修改。具体来说，不再将生成的数据标记为主模型认为的最可能类别（“硬标签”），而是用所有可能类别的预测概率（“软标签”）来标记这些数据（参见“方法”部分）。这种方法称为“蒸馏”（distillation），已被证明是一种在模型之间传递信息或知识的有效方式。特别是在生成数据质量较低的情况下，我们认为这种标记重放样本的方式尤为重要，因为如果将模糊的输入（例如同时接近多个类别的输入）硬性标记为单一类别，可能会对模型造成不利影响。

> [!note] 
> 这段实际上是指：由解码器生成的用来回放的内容实际上是软标签，不是硬标签。而输入的用来学习的数据仍然是硬标签。

### 评估大脑启发的重放方法

为了测试这些修改的有效性，我们将所提出的大脑启发的重放方法应用于之前相同的基准测试，同时使用了类似规模的网络。在 **Permuted MNIST 协议**（100个排列）中，我们发现大脑启发的重放方法的性能优于已经表现很强的 **SI**（图 5b）。将大脑启发的重放与 **SI** 结合后，性能进一步提升，在测试时任务身份信息不可用的情况下达到了这一基准测试的最新性能水平。

在 **split CIFAR-100 协议** 中，我们的大脑启发修改显著提升了生成重放（GR）的性能。在 **Task-IL 场景** 下，大脑启发的重放几乎完全消除了灾难性遗忘，并且其性能优于 **EWC**、**SI** 和 **LwF**（图 6b）。在 **Class-IL 场景** 下，大脑启发的重放也超越了其他方法，尽管其性能仍显著低于“上限”——即始终使用所有类别数据进行训练的情况（图 6c）。然而，我们尚未发现任何不存储数据的持续学习方法在这个具有挑战性的问题上表现得更好。最后，与 **permuted MNIST** 类似，将大脑启发的重放与 **SI** 结合后，性能再次显著提升，进一步缩小了与联合训练（上限）之间的差距（图 6c）。


### 损伤实验

为了深入了解我们提出的大脑启发的重放方法中各组件的贡献，我们进行了系列的添加和移除实验（图 8）。**内部重放**是影响最大的修改，因为引入或移除这一组件对性能的影响最大。但我们也发现，不同的修改之间具有互补性。对于 **permuted MNIST**（图 8a）和 **CIFAR-100 的 Class-IL 场景**（图 8c），将所有组件结合起来带来的性能提升大于单独添加每个组件的效果之和。尤其是**条件重放**和**基于内部上下文的门控**的益处依赖于它们与其他组件的结合。此外，无论是 permuted MNIST 还是 CIFAR-100 的 Class-IL 场景，**单独的任何修改都不足以达到大脑启发重放的整体性能**，而且除了 **RtF**（通过反馈进行重放），其他组件都是必要的。**RtF** 的主要贡献在于提高了效率（例如，不需要单独的生成模型），而对性能的影响不大。尽管当大脑启发重放与 **SI** 结合时，移除 **RtF** 会轻微降低平均准确率（permuted MNIST：0.904±0.005 对比 0.892±0.004；CIFAR-100 的 Class-IL：0.344±0.002 对比 0.334±0.002），因此最佳的整体性能实际上是在包含 **RtF** 时获得的。最后，在 **CIFAR-100 的 Task-IL 场景**（图 8b）中，**没有任何单独的组件是必要的**，这反映了在这一场景下防止灾难性遗忘要容易得多。

> [!figure]
> ![[files/Pasted image 20250105111433.png]]
> ![[files/Pasted image 20250105111441.png]]
> ![[files/Pasted image 20250105111458.png]]
> **图 8**：通过添加和移除实验分解各个修改的贡献  
图中显示了 **标准生成重放（GR）** 中逐一添加单个修改（“+”，左侧）和 **大脑启发的重放（BI-R）** 中逐一移除单个修改（“-”，右侧）对平均整体准确率的影响。具体结果包括：
> - **a. Permuted MNIST 协议（100 个排列）**
> - **b. CIFAR-100 的任务增量学习场景（Task-IL）**
> - **c. CIFAR-100 的类别增量学习场景（Class-IL）**
> 
请注意，由于该协议未使用卷积层，**内部重放**未在 **Permuted MNIST** 上应用。每个柱状图反映了 5 次（Permuted MNIST）或 10 次（CIFAR-100）实验的均值，误差条为 ±1 SEM，单次实验结果用点表示。灰色虚线表示随机表现水平，黑色实线显示了仅在最后一个任务/阶段上训练的基准网络性能（均值基于 5 次或 10 次实验，阴影区域为 ±1 SEM），可以解释为在除最后一个任务外所有数据上的随机表现。
> - **rtf**：通过反馈进行重放（Replay-through-feedback）
> - **con**：条件重放（Conditional replay）
> - **gat**：基于内部上下文的门控（Gating based on internal context）
> - **int**：内部重放（Internal replay）
> - **dis**：蒸馏（Distillation）

### 生成重放的质量
为了更好地理解大脑启发的重放方法为何表现如此优秀，我们对比了生成器在有无各种修改情况下的质量。特别是，我们探讨了**在内部表示层重放是否比在像素级重放生成更高质量的样本**。然而，这一测试并不简单。通过视觉比较样本是不可能的，因为生成的内部表示难以被可视化。用于评估 VAE 的传统定量指标（如重建误差或平均对数似然）在比较不同输入分布的模型时存在问题（尽管这些指标可以用于像素级重放和内部重放的比较，见补充图 4）。为了公平地比较在不同层级生成的样本，必须首先将它们转换到一个**共同的嵌入空间**。巧合的是，最近用于评估生成模型的方法（如 **Inception Score (IS)**、**Fréchet Inception Distance (FID)** 和 **Precision & Recall 曲线**）的第一步，正是将样本嵌入到一个不同的特征空间中。原始版本的这些指标通过 **Inception Net** 将样本嵌入到特征空间中，但我们的生成的内部表示无法直接输入到该网络。因此，我们用一个替代神经网络取代了 **Inception Net**，该网络与增量训练模型具有相同的预训练卷积层（见“方法”部分及参考文献 55）。这样，像素级和内部表示生成的样本都可以通过这个网络嵌入到相同的特征空间中。


对于 CIFAR-100 的 Class-IL 场景，我们的修改版 **IS**（图 9a）和 **FID**（图 9b）指标均表明，大脑启发的重放方法所生成的重放样本确实优于标准生成重放（GR）。与图 8c 的结果一致，这种改进很大程度上归因于在内部（隐藏层）而非像素级别进行重放，同时其他修改（及其组合）也有所贡献。然而，这两个指标的一个问题是，它们只能通过单一数值来量化生成器的性能，无法区分样本的**质量**和**多样性**。为了测试生成样本的改进主要是由于质量提升还是多样性提升，图 9c 报告了我们版本的 **Precision & Recall** 曲线。这些曲线表明，我们的修改在提升样本质量和多样性方面有着类似的贡献。

> [!figure]
> ![[files/Pasted image 20250105113818.png]]
> ### 图 9：生成样本的质量和多样性
> 在 CIFAR-100 的类别增量学习（Class-IL）场景中，比较了**标准生成重放（GR）** 添加单个修改（“+”，每个面板的左侧）与**大脑启发的重放（BI-R）** 移除单个修改（“-”，每个面板的右侧）所生成样本的质量和多样性。
> - **a. 修改版 Inception Score（Modified IS）**：
>     
>     - 指标越高，样本质量越好。
>     - 显示了不同修改对生成样本质量的贡献。
> - **b. 修改版 Frechet Inception Distance（Modified FID）**：
>     
>     - 指标越低，样本质量越好。
>     - 展示了各修改对生成器性能的影响。
> - **c. Precision & Recall 曲线**：
>     
>     - **靠近顶部**表示样本质量（Precision）更高。
>     - **靠近右侧**表示样本多样性（Recall）更高。
>     - 曲线展示了样本质量和多样性之间的权衡，并比较了不同方法的平衡表现。
> ### **说明**：
> 
> 1. **评估条件**：
>     
>     - 所有指标基于模型增量训练完成全部 100 个类别后生成的样本。
>     - 在 **b** 和 **c** 面板中，生成样本与测试集中的真实样本进行了比较。
> 2. **误差条与重复实验**：
>     
>     - 每个柱状图或粗线表示 10 次重复实验的平均值，误差条为 ±1 SEM，单次实验结果用点或细线表示。
> 3. **修改对比**：
>     
>     - **rtf**（通过反馈进行重放）
>     - **con**（条件重放）
>     - **gat**（基于内部上下文的门控）
>     - **int**（内部重放）
>     - **dis**（蒸馏）
> 

## 讨论
**人工神经网络（ANNs）中的灾难性遗忘**是人工智能系统从其经验中逐步学习的主要障碍之一。相比之下，生物神经网络在持续学习方面优于人工神经网络，因此，受大脑启发以缓解人工神经网络中灾难性遗忘的尝试不足为奇：基于正则化的方法（如 EWC 和 SI）模拟了生物突触的复杂性，而大脑根据上下文不同处理刺激的能力则启发了显式基于任务的方法（如 XdG）。我们证明了，尽管这些方法在需要逐步学习任务的场景中是成功的，但它们无法逐步学习新的类别。只有另一种神经科学启发的方法，即重放先前观察的代表性样本，被发现能够解决 Class-IL 问题。重要的是，这种重放不需要依赖于存储的数据，因为可以生成用于重放的样本。进一步支持重放的是，我们发现即使是低质量的样本或每个小批量中仅包括一个重放样本也可能足够。然而，事实证明，对于更具挑战性的问题（例如以自然图像作为输入的问题），简单的生成重放（GR）实现会失效。为了解决这一问题，我们从大脑中获得了启发，提出了一系列简单、易于实现且高效的修改，并展示了这些修改如何使生成重放成功扩展到具有许多任务或复杂输入的问题。

本研究中所考虑的持续学习问题均涉及图像分类，这引发了一个问题：这里获得的见解在多大程度上适用于其他机器学习领域或其他输入模态。首先，尽管分类确实是最终目标，我们也展示了生成重放（GR）促进了生成模型的增量学习，并且我们的大脑启发修改提高了学习到的生成模型的质量。然而，需要注意的是，在半监督或无监督的设置中，**条件重放**和**基于内部上下文的门控**组件需要被修改，因为它们当前的实现依赖于训练期间类别标签的可用性。可能可以改为依赖其他上下文信息。在强化学习中，重放先前经验的情节已经是一个广泛使用的工具，但目前它依赖于存储这些情节的记忆缓冲区。未来的研究可以测试大脑启发的 GR 是否能够消除或减少对存储数据的依赖。其次，关于输入模态，尽管本研究中仅报告了基于图像的实验，但大多数结果和提出的方法应该能够扩展到其他模态。特别是，在 MNIST 上的实验中并未使用特定于图像的工具。仅将**内部重放**组件转化为其他输入模态并不简单，因为该组件依赖于预训练的卷积层。类似于大脑中的独立感觉处理区域，其他输入模态需要不同的预处理层，尚需验证内部表示的重放是否能在这些情况下起作用。内部重放的另一个缺点是，刚性的预训练卷积层可能限制模型学习分布外输入的能力（例如，不符合自然图像统计的图像），尽管在某种程度上，这在大脑中也是如此。最后，目前研究的另一个局限是，持续学习的性能仅通过所有已见任务或类别的平均准确率来量化，这主要反映了一种方法遭受灾难性遗忘的程度。其他持续学习的重要方面（例如正向和反向迁移或压缩性）并未被明确讨论。特别是对于 Task-IL——其中灾难性遗忘可以通过为每个要学习的任务单独训练一个网络来防止——可以认为这些其他方面更具研究意义。然而，对于 Class-IL，防止灾难性遗忘仍是一个未解决的问题，因此我们专注于平均准确率这一指标是合理的。

除了利用神经科学的见解来改进人工神经网络（ANNs）的持续学习，本研究的另一个目标是为大脑中重放的计算作用及其可能的实现方式生成新的视角和假设。关于重放的实现，本研究首先提供了证据，表明重放可能确实是大脑用来对抗灾难性遗忘的一种可行方法。尽管长期以来已知重新访问之前见过的示例可以在玩具问题中防止灾难性遗忘，但重放是否可以扩展到更复杂的真实世界问题而无需依赖生物学上不合理的机制（如显式存储过去的观察）仍是一个开放性问题。此外，我们的工作提出了一个假设，即大脑中的重放是一种生成过程。这一假设与越来越多的实验研究一致，这些研究报告称大脑中重放的表示并不直接反映实际经历，而可能是从一个学习到的世界模型中采样得来的。关于重放的功能，我们的发现突出了重放在增量学习新类别或分类中的重要计算作用。能够区分事物或对象对生存至关重要，关于分类学习的计算模型也有大量的认知科学文献。然而，这些模型通常假设所有类别的示例要么同时观察到，要么可以直接存储在记忆中（例如基于示例、原型和规则的模型都依赖这一假设）。生成重放（GR）可能是一种生物学上合理的方法，用于将这些模型扩展到更加自然的场景中，在这种场景中，不同类别是依次提供的。最后，我们还应注意到，大脑启发的重放方法缺少一些大脑中重放的重要方面。其中之一是时间结构：大脑中的重放事件由反映实际经历时间顺序的神经活动序列组成。Parisi 等人最近提出了一种结合这种序列重放的持续学习方法。他们的方法与我们的内部重放组件在概念上有一些相似之处，例如他们也使用预训练卷积层作为特征提取器，并且重放网络嵌入而不是像素级图像。然而，一个重要的区别是他们的方法并不学习显式生成模型来生成这些嵌入，而是通过递归自组织网络存储它们。这种方法的一个缺点是，它依赖于为每次新体验生成新的神经元，这让人怀疑他们的方法是否可以扩展到我们这里所考虑的协议。

**一个引人入胜的问题是，为什么生成重放（GR）在 Class-IL 场景下比基于正则化的方法（如 EWC 和 SI）更有效。**  一个可能的答案与这些不同方法如何存储和维持之前遇到的类别的记忆有关。GR 在网络的函数或输出空间中维持这些记忆，因为该方法学习生成网络不应遗忘的输入-输出组合。而另一方面，基于正则化的方法完全在网络的参数空间中存储和维持之前类别的记忆，因为它们唯一的工具是改变参数的可塑性。特别是在 Class-IL 场景下，这可能是一个挑战，因为所有关于之前类别的信息都必须被保留，因为未来类别的信息是未知的。而在 Task-IL 场景中，需要存储的记忆相对简单，因为只需要记住当时学习的特定任务的重要特征。尽管如此，我们希望强调，尽管我们发现当前基于正则化的方法自身无法解决 Class-IL 问题，但当它们与 GR 结合时，却提供了独特的贡献。我们假设这是因为在函数空间中维持记忆和在参数空间中维持记忆各有其独特的挑战：
- 对于 GR，挑战在于学习一个生成网络，以捕捉之前任务/类别的本质；
- 而对于基于正则化的方法，挑战在于如何正确地将贡献归因于网络的参数。
这表明，正则化（或元可塑性）和重放是互补的机制，这与经验观察一致——大脑同时使用这两种策略（大致对应于细胞和系统整合）来保护其记忆。



## 方法
### 任务

1. **Split MNIST 任务协议**：MNIST 数据集被分为五个任务或阶段，每个任务/阶段包含两个数字。使用了原始的 28×28 像素灰度图像，未进行任何预处理。我们采用了标准的训练/测试划分，得到 60,000 张训练图像（每个数字约 6,000 张）和 10,000 张测试图像（每个数字约 1,000 张）。
2. **Permuted MNIST**：原始 MNIST 图像首先被零填充至 32×32 像素。对于每个任务，生成并应用一个随机像素排列至这 1024 个像素。未进行其他预处理。我们使用了包含 100 个任务的序列，其中每个任务是一个十分类任务，目标是识别原始数字。同样采用标准的训练/测试划分，每个任务有 60,000 张训练图像和 10,000 张测试图像。
3. **Split CIFAR-100**：CIFAR-100 数据集被分为十个任务或阶段，每个任务/阶段包含十个类别。原始的 32×32 像素 RGB 彩色图像进行了归一化处理（即每个像素值减去相关通道的均值并除以相关通道的标准差，均值和标准差基于所有训练图像计算），但未进行其他预处理或增强。同样采用标准的训练/测试划分，得到 50,000 张训练图像（每个类别 500 张）和 10,000 张测试图像（每个类别 100 张）。

### 神经网络架构
#### 总体结构
**为了公平比较，所有被比较方法使用了相同的基础神经网络结构。**
- **Split MNIST**：基础神经网络是一个全连接网络，包含两层隐藏层，每层有 400 个节点，以及一个 softmax 输出层。所有隐藏节点使用 ReLU 激活函数。
    
- **Permuted MNIST**：基础神经网络是一个全连接网络，包含两层隐藏层，每层有 2000 个节点，以及一个 softmax 输出层。所有隐藏节点使用 ReLU 激活函数。
    
- **Split CIFAR-100**：基础神经网络结构包含 5 层预训练的卷积层（见下文），随后是两层全连接层，每层包含 2000 个节点，使用 ReLU 激活函数，以及一个 softmax 输出层。

#### 单元激活
- **Task-IL 和 Class-IL 场景**：
    - 在这两个场景中，输出层始终为每个需要学习的类别设置单独的输出单元（例如，Split MNIST 中有 10 个输出单元，Split CIFAR-100 中有 100 个输出单元）。
    - 但这两个场景的区别在于这些输出单元何时“激活”：
        - **Task-IL 场景**：输出层是“多头”的（multi-headed），这意味着仅当前任务或被重放任务的类别对应的输出单元是激活的。
        - **Class-IL 场景**：输出层是“单头”的（single-headed），这意味着所有已遇到类别的输出单元始终激活。
- **Permuted MNIST（Domain-IL 场景）**：
    - 输出层为每个数字设置一个输出单元（即共有 10 个输出单元）。
    - 在整个过程中，所有输出单元始终激活。

#### Softmax的使用
某个输出单元在给定任务中是否激活决定了网络是否可以为相应类别分配正概率：softmax 输出层执行的归一化仅考虑激活的节点。即，神经网络预测输入 $x$ 属于类别 $c$ 的条件概率计算为：

$$p_\theta(Y = c | x) = \begin{cases} \frac{e^{z_c(x)}}{\sum_{j} e^{z_j(x)}}, & \text{如果输出节点 } c \text{ 被激活} \\ 0, & \text{其他情况} \end{cases}$$

其中，$z_c^{(x)}$是通过神经网络（由参数 $\theta$ 表示）对输入$x$计算出的类别$c$的未归一化概率或“logit”（注意$z_c^{(x)}$也依赖于 $\theta$，但为了简化符号，这种依赖性未被明确表示），分母中的求和是对输出层中所有被激活的节点进行的。

### 训练

#### 训练目标
目标始终是按照任务协议的所有任务或阶段依次对神经网络进行训练，其中网络仅能访问当前任务/阶段的数据。对于本文中讨论的所有方法，在训练过程中，神经网络的参数 $\theta$ 使用小批量**随机梯度下降**（mini-batch stochastic gradient descent, SGD）在特定于任务的损失函数（$\mathcal L_{\text{total}}$ ）上进行更新。

损失函数的具体形式因方法而异，但核心部分始终是当前任务数据上的标准多类交叉熵分类损失。对于一个带有硬目标 $y$ 的输入$x$，每个样本的分类损失定义为：
$$ \mathcal L^C(x, y; \theta) = -\log p_\theta(Y = y | x), $$
其中，$p_\theta$ 是由神经网络定义的条件概率分布。

> [!info]
> SGD是指在梯度下降的过程中每一步不使用全部的数据，而是在样本中抽取一些数据来加快速度
#### 训练设置
1. **迭代次数：**
    - **2000次迭代**：用于splitMNIST和permutedMNIST。
    - **5000次迭代**：用于splitCIFAR-100。
2. **优化器：**
    - 使用**ADAM优化器**，参数设置为：
        - **β₁ = 0.9**（一阶动量的指数衰减率）。
        - **β₂ = 0.999**（二阶动量的指数衰减率）。
3. **学习率：**
    - splitMNIST的学习率为**0.001**。
    - permutedMNIST和splitCIFAR-100的学习率为**0.0001**。
4. **小批量大小（mini-batch size）：**
    - splitMNIST的批量大小为**128**。
    - permutedMNIST和splitCIFAR-100的批量大小为**256**。
5. **重放机制（Replay）：**
    - 如果使用了重放机制，则用于计算 $\mathcal L_{\text{replay}}$的重放样本数量与当前任务的样本数量相同（见下文说明）。
    - 唯一的例外是用于**图4a**的实验中，重放样本的小批量大小被系统性地改变，而当前任务的批量大小始终保持为128。

### 基线方法
为了评估比较方法在缓解灾难性遗忘方面的效果，我们在每次比较中都包含了两个基线方法：
1. **天真基线（Naive Baseline）**：  
    基础神经网络以标准方式依次对所有任务进行训练（即损失函数始终为当前任务数据的分类损失：
2. **上限（Upper Bound）**：  
    基础神经网络始终使用到目前为止所有任务的训练数据进行训练（“联合训练”或“离线训练”），这是方法性能的理论上限。

### 用于生成回放（GR）的主模型
对于标准生成回放（GR），两个模型依次被训练以完成所有任务：
1. **主模型（main model）**：用于实际解决任务。
2. **单独的生成模型（generative model）**：用于生成代表先前学习任务的输入数据。
主模型是一个具有基础神经网络结构的分类器。用于训练该模型的损失函数由两部分组成：一部分针对当前任务的数据，另一部分针对回放数据。这两部分的权重根据模型迄今为止所见任务/阶段的数量进行调整：
$$
\mathcal L_{\text{total}} = \frac{1}{N_{\text{tasks so far}}}\mathcal L_{\text{current}} + \left(1 - \frac{1}{N_{\text{tasks so far}}}\right)\mathcal L_{\text{replay}}
$$
- 其中，$\mathcal L_\text{current}$ 是当前任务数据上的标准分类损失，
- $\mathcal L_\text{replay}$是回放数据上的标准分类损失，
- $N_\text{task so far}$表示模型迄今为止所见的任务数量。
对于标准生成回放（standard GR），上述公式中的$\mathcal L_\text{current}$和$\mathcal L_\text{replay}$均为当前任务数据和回放数据上的标准分类损失。

### 用于生成回放（GR）的生成器
对于生成模型，我们使用了对称的变分自编码器（VAE）【参考28,71】。  
一个 VAE 包括：
1. **编码器网络** $q\phi$：将输入向量$x$映射到一个随机潜变量向量$z$。
2. **解码器网络** $p\psi$：将潜变量$z$映射到一个重建或解码的输入向量$\hat x$。
我们将编码器和解码器的结构设计为与基础神经网络相似：
- 对于基于 MNIST 的协议（split MNIST 和 permuted MNIST），编码器和解码器是完全连接的网络，具有两个隐藏层，每层包含 400（split MNIST）或 2000（permuted MNIST）个单元，采用 ReLU 非线性激活函数。
- 对于 split CIFAR-100 数据集，编码器由五个预训练的卷积层组成（见下文），后接两个完全连接的隐藏层，每层包含 2000 个 ReLU 单元；解码器包括两个完全连接的隐藏层，每层 2000 个 ReLU 单元，后接五个反卷积层（见下文）。
随机潜变量层$z$始终包含100个维度，其由均值$\mu(x)$和标准差$\sigma(x)$参数化（这些值是编码器网络$q\phi$在输入$x$上的输出），其先验分布为标准正态分布。
通常，VAE 的参数（记为 ϕϕϕ 和 ψψψ）通过最大化观测数据的变分下界（ELBO）来训练，这等价于最小化输入 xxx 的以下每样本损失函数：
$$\begin{align}
L_G(x; ϕ, ψ) =& \mathbb{E}_{z \sim q_ϕ(\cdot | x)} \left[ -\log p_ψ(x | z) \right] + D_{\text{KL}}(q_ϕ(\cdot | x) \| p(\cdot))\\
=&\mathcal L_{\text{recon}}(x; ϕ, ψ) + \mathcal L_{\text{latent}}(x; ϕ).
\end{align}
$$
其中：
- $q_{\phi}(\cdot|x) = \mathcal N(\mu(x),\sigma(x)^2I)$：编码器定义的潜变量$z$的后验分布
- $p(\cdot) = \mathcal N(0,I)$：潜变量的先验分布
- $D_{KL}$：kullback-Leibler散度


